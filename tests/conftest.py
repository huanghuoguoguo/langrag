"""Pytest configuration and global fixtures for LangRAG tests."""

import tempfile
from pathlib import Path
from typing import List
import pytest

from langrag.core.document import Document
from langrag.core.chunk import Chunk
from langrag import RAGConfig, ComponentConfig
from langrag.config.models import VectorStoreConfig


# Import shared fixtures from fixtures module
from tests.fixtures.common import (
    sample_documents_content,
    sample_document_files,
    sample_chunks,
    sample_search_results,
    minimal_rag_config,
    duckdb_rag_config,
    large_document_file,
    multilingual_document_files,
    empty_document_file,
    special_chars_document_file,
    temp_workspace
)


# ==================== ä¸´æ—¶ç›®å½•å¤¹å…· ====================

@pytest.fixture
def temp_dir():
    """æä¾›ä¸´æ—¶ç›®å½•ï¼Œæµ‹è¯•ç»“æŸåè‡ªåŠ¨æ¸…ç†

    Returns:
        Path: ä¸´æ—¶ç›®å½•è·¯å¾„
    """
    with tempfile.TemporaryDirectory() as tmpdir:
        yield Path(tmpdir)


@pytest.fixture
def temp_file(temp_dir):
    """æä¾›ä¸´æ—¶æ–‡ä»¶ï¼Œæµ‹è¯•ç»“æŸåè‡ªåŠ¨æ¸…ç†

    Returns:
        Path: ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    """
    file_path = temp_dir / "test_file.txt"
    file_path.write_text("Sample content for testing")
    return file_path


# ==================== ç¤ºä¾‹æ•°æ®å¤¹å…· ====================

@pytest.fixture
def sample_text():
    """æä¾›ç¤ºä¾‹æ–‡æœ¬æ•°æ®

    Returns:
        str: ç¤ºä¾‹æ–‡æœ¬
    """
    return """
    Retrieval-Augmented Generation (RAG) is a technique that combines
    information retrieval with large language models. RAG retrieves
    relevant documents from a knowledge base and uses them to generate
    more accurate and contextual responses.

    Vector databases are essential for RAG systems as they enable
    efficient semantic search over large document collections.
    """


@pytest.fixture
def sample_documents() -> List[Document]:
    """æä¾›ç¤ºä¾‹æ–‡æ¡£åˆ—è¡¨

    Returns:
        List[Document]: æ–‡æ¡£åˆ—è¡¨
    """
    return [
        Document(
            content="RAG combines retrieval and generation for better AI responses.",
            metadata={"source": "doc1.txt", "author": "Alice"}
        ),
        Document(
            content="Vector databases enable semantic search in RAG systems.",
            metadata={"source": "doc2.txt", "author": "Bob"}
        ),
        Document(
            content="Embedding models convert text into numerical vectors.",
            metadata={"source": "doc3.txt", "author": "Charlie"}
        ),
    ]


@pytest.fixture
def sample_chunks() -> List[Chunk]:
    """æä¾›ç¤ºä¾‹ chunk åˆ—è¡¨ï¼ˆå¸¦ embeddingï¼‰

    Returns:
        List[Chunk]: Chunk åˆ—è¡¨
    """
    return [
        Chunk(
            id="chunk-1",
            content="RAG combines retrieval and generation.",
            embedding=[0.1] * 384,
            source_doc_id="doc1.txt",
            metadata={"position": 0}
        ),
        Chunk(
            id="chunk-2",
            content="Vector databases enable semantic search.",
            embedding=[0.2] * 384,
            source_doc_id="doc2.txt",
            metadata={"position": 0}
        ),
        Chunk(
            id="chunk-3",
            content="Embedding models convert text to vectors.",
            embedding=[0.3] * 384,
            source_doc_id="doc3.txt",
            metadata={"position": 0}
        ),
    ]


# ==================== ç»„ä»¶å¤¹å…· ====================

@pytest.fixture
def simple_embedder():
    """æä¾›ç®€å•çš„åµŒå…¥å™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰

    Returns:
        BaseEmbedder: ç®€å•åµŒå…¥å™¨å®ä¾‹
    """
    from langrag.embedder import SimpleEmbedder
    return SimpleEmbedder(dimension=384)


@pytest.fixture
def recursive_chunker():
    """æä¾›é€’å½’åˆ†å—å™¨

    Returns:
        RecursiveCharacterChunker: åˆ†å—å™¨å®ä¾‹
    """
    from langrag.chunker.providers.recursive_character import RecursiveCharacterChunker
    return RecursiveCharacterChunker(chunk_size=500, chunk_overlap=50)


@pytest.fixture
def simple_text_parser():
    """æä¾›ç®€å•æ–‡æœ¬è§£æå™¨

    Returns:
        SimpleTextParser: è§£æå™¨å®ä¾‹
    """
    from langrag.parser import SimpleTextParser
    return SimpleTextParser()


@pytest.fixture
def in_memory_vector_store():
    """æä¾›å†…å­˜å‘é‡å­˜å‚¨

    Returns:
        InMemoryVectorStore: å‘é‡å­˜å‚¨å®ä¾‹
    """
    from langrag.vector_store import InMemoryVectorStore
    return InMemoryVectorStore()


# ==================== Mock å¤¹å…· ====================

@pytest.fixture
def mock_embedder(mocker):
    """æä¾› Mock åµŒå…¥å™¨

    Returns:
        Mock: Mock åµŒå…¥å™¨å¯¹è±¡
    """
    from langrag.embedder import BaseEmbedder
    mock = mocker.Mock(spec=BaseEmbedder)
    mock.embed.return_value = [[0.1] * 384]
    mock.dimension = 384
    return mock


@pytest.fixture
def mock_vector_store(mocker):
    """æä¾› Mock å‘é‡å­˜å‚¨

    Returns:
        Mock: Mock å‘é‡å­˜å‚¨å¯¹è±¡
    """
    from langrag.vector_store import BaseVectorStore
    from langrag.vector_store.capabilities import VectorStoreCapabilities

    mock = mocker.Mock(spec=BaseVectorStore)
    mock.capabilities = VectorStoreCapabilities(
        supports_vector=True,
        supports_fulltext=False,
        supports_hybrid=False
    )
    mock.count.return_value = 0
    return mock


# ==================== RAG å¼•æ“å¤¹å…· ====================

@pytest.fixture
def minimal_rag_config():
    """æä¾›æœ€å°åŒ–çš„ RAG é…ç½®

    Returns:
        RAGConfig: RAG é…ç½®å¯¹è±¡
    """
    from langrag.config.models import RAGConfig, ComponentConfig

    return RAGConfig(
        parser=ComponentConfig(type="simple_text", params={}),
        chunker=ComponentConfig(type="recursive", params={"chunk_size": 500}),
        embedder=ComponentConfig(type="simple", params={"dimension": 384}),
        vector_store=ComponentConfig(type="in_memory", params={}),
    )


@pytest.fixture
def rag_engine(minimal_rag_config):
    """æä¾› RAG å¼•æ“å®ä¾‹

    Returns:
        RAGEngine: RAG å¼•æ“å®ä¾‹
    """
    from langrag.engine import RAGEngine
    return RAGEngine(minimal_rag_config)


# ==================== æµ‹è¯•æ ‡è®°å¤„ç† ====================

def pytest_configure(config):
    """é…ç½® pytestï¼Œæ·»åŠ è‡ªå®šä¹‰æ ‡è®°"""
    config.addinivalue_line(
        "markers", "unit: Unit tests - å¿«é€Ÿã€éš”ç¦»çš„å•å…ƒæµ‹è¯•"
    )
    config.addinivalue_line(
        "markers", "integration: Integration tests - ç»„ä»¶é—´åä½œæµ‹è¯•"
    )
    config.addinivalue_line(
        "markers", "e2e: End-to-end tests - å®Œæ•´ä¸šåŠ¡æµç¨‹æµ‹è¯•"
    )
    config.addinivalue_line(
        "markers", "smoke: Smoke tests - å¿«é€ŸéªŒè¯æ ¸å¿ƒåŠŸèƒ½"
    )
    config.addinivalue_line(
        "markers", "slow: Slow tests - æ‰§è¡Œæ—¶é—´ > 1s çš„æµ‹è¯•"
    )


def pytest_collection_modifyitems(config, items):
    """æ ¹æ®æ–‡ä»¶è·¯å¾„è‡ªåŠ¨æ·»åŠ æ ‡è®°"""
    for item in items:
        # è·å–æµ‹è¯•æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
        rel_path = Path(item.fspath).relative_to(Path(__file__).parent)

        # æ ¹æ®ç›®å½•è‡ªåŠ¨æ·»åŠ æ ‡è®°
        if "unit" in rel_path.parts:
            item.add_marker(pytest.mark.unit)
        elif "integration" in rel_path.parts:
            item.add_marker(pytest.mark.integration)
        elif "e2e" in rel_path.parts:
            item.add_marker(pytest.mark.e2e)
        elif "smoke" in rel_path.parts:
            item.add_marker(pytest.mark.smoke)


# ==================== æµ‹è¯•ä¼šè¯é’©å­ ====================

def pytest_sessionstart(session):
    """æµ‹è¯•ä¼šè¯å¼€å§‹æ—¶çš„é’©å­"""
    print("\n" + "="*70)
    print("ğŸ§ª Starting LangRAG Test Suite")
    print("="*70)


def pytest_sessionfinish(session, exitstatus):
    """æµ‹è¯•ä¼šè¯ç»“æŸæ—¶çš„é’©å­"""
    print("\n" + "="*70)
    if exitstatus == 0:
        print("âœ… All tests passed!")
    else:
        print("âŒ Some tests failed")
    print("="*70)
