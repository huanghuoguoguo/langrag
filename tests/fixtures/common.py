"""Shared test fixtures for all test types.

è¿™ä¸ªæ¨¡å—æä¾›å¯åœ¨æ‰€æœ‰æµ‹è¯•ä¸­é‡å¤ä½¿ç”¨çš„fixturesã€‚
"""

import pytest
import tempfile
from pathlib import Path
from typing import List

from langrag import (
    Document,
    Chunk,
    SearchResult,
    RAGConfig,
    ComponentConfig
)
from langrag.config.models import VectorStoreConfig


@pytest.fixture
def sample_documents_content() -> List[str]:
    """æä¾›ç¤ºä¾‹æ–‡æ¡£å†…å®¹åˆ—è¡¨"""
    return [
        "Machine learning is a subset of artificial intelligence. "
        "It focuses on teaching computers to learn from data. "
        "Common algorithms include neural networks, decision trees, and support vector machines.",

        "Python is a high-level programming language. "
        "It is widely used in data science, web development, and automation. "
        "Python has a simple syntax that makes it easy to learn.",

        "Natural language processing (NLP) is a field of AI. "
        "It deals with the interaction between computers and human language. "
        "Applications include chatbots, translation, and sentiment analysis."
    ]


@pytest.fixture
def sample_document_files(tmp_path, sample_documents_content) -> List[Path]:
    """åˆ›å»ºåŒ…å«ç¤ºä¾‹å†…å®¹çš„ä¸´æ—¶æ–‡ä»¶"""
    files = []
    for i, content in enumerate(sample_documents_content):
        file_path = tmp_path / f"doc_{i}.txt"
        file_path.write_text(content, encoding="utf-8")
        files.append(file_path)
    return files


@pytest.fixture
def sample_chunks() -> List[Chunk]:
    """æä¾›ç¤ºä¾‹Chunkåˆ—è¡¨ç”¨äºæµ‹è¯•"""
    return [
        Chunk(
            id="chunk_1",
            content="Python is a programming language",
            embedding=[1.0, 0.0, 0.0],
            source_doc_id="doc_1",
            metadata={"topic": "python", "page": 1}
        ),
        Chunk(
            id="chunk_2",
            content="Machine learning uses algorithms",
            embedding=[0.0, 1.0, 0.0],
            source_doc_id="doc_2",
            metadata={"topic": "ml", "page": 1}
        ),
        Chunk(
            id="chunk_3",
            content="Natural language processing is AI",
            embedding=[0.0, 0.0, 1.0],
            source_doc_id="doc_3",
            metadata={"topic": "nlp", "page": 1}
        ),
    ]


@pytest.fixture
def sample_search_results(sample_chunks) -> List[SearchResult]:
    """æä¾›ç¤ºä¾‹SearchResultåˆ—è¡¨"""
    return [
        SearchResult(chunk=sample_chunks[0], score=0.95),
        SearchResult(chunk=sample_chunks[1], score=0.85),
        SearchResult(chunk=sample_chunks[2], score=0.75),
    ]


@pytest.fixture
def minimal_rag_config() -> RAGConfig:
    """æä¾›æœ€å°RAGé…ç½®ç”¨äºæµ‹è¯•"""
    return RAGConfig(
        parser=ComponentConfig(type="simple_text"),
        chunker=ComponentConfig(type="fixed_size", params={"chunk_size": 200, "overlap": 50}),
        embedder=ComponentConfig(type="mock", params={"dimension": 384, "seed": 42}),
        vector_store=VectorStoreConfig(type="in_memory"),
        reranker=ComponentConfig(type="noop")
    )


@pytest.fixture
def duckdb_rag_config(tmp_path) -> RAGConfig:
    """æä¾›ä½¿ç”¨DuckDBçš„RAGé…ç½®"""
    db_path = tmp_path / "test.duckdb"
    return RAGConfig(
        parser=ComponentConfig(type="simple_text"),
        chunker=ComponentConfig(type="fixed_size", params={"chunk_size": 200}),
        embedder=ComponentConfig(type="mock", params={"dimension": 128, "seed": 42}),
        vector_store=VectorStoreConfig(
            type="duckdb",
            params={"database_path": str(db_path), "vector_dimension": 128}
        ),
        reranker=ComponentConfig(type="noop")
    )


@pytest.fixture
def large_document_file(tmp_path) -> Path:
    """åˆ›å»ºä¸€ä¸ªå¤§æ–‡æ¡£ç”¨äºæµ‹è¯•åˆ†å—"""
    file_path = tmp_path / "large_doc.txt"

    # åˆ›å»ºå¤§çº¦5000å­—çš„æ–‡æ¡£
    paragraphs = [
        "Artificial intelligence has revolutionized many industries.",
        "Machine learning algorithms can learn patterns from data.",
        "Deep learning uses neural networks with multiple layers.",
        "Natural language processing enables computers to understand text.",
        "Computer vision allows machines to interpret visual information.",
    ]

    # é‡å¤è¿™äº›æ®µè½ä»¥åˆ›å»ºå¤§æ–‡æ¡£
    content = "\n\n".join(paragraphs * 100)
    file_path.write_text(content, encoding="utf-8")

    return file_path


@pytest.fixture
def multilingual_document_files(tmp_path) -> List[Path]:
    """åˆ›å»ºå¤šè¯­è¨€æ–‡æ¡£ç”¨äºæµ‹è¯•"""
    files = []

    # è‹±æ–‡æ–‡æ¡£
    en_file = tmp_path / "english.txt"
    en_file.write_text(
        "This is an English document about artificial intelligence and machine learning.",
        encoding="utf-8"
    )
    files.append(en_file)

    # ä¸­æ–‡æ–‡æ¡£
    zh_file = tmp_path / "chinese.txt"
    zh_file.write_text(
        "è¿™æ˜¯ä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ çš„ä¸­æ–‡æ–‡æ¡£ã€‚æ·±åº¦å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ã€‚",
        encoding="utf-8"
    )
    files.append(zh_file)

    # æ··åˆæ–‡æ¡£
    mixed_file = tmp_path / "mixed.txt"
    mixed_file.write_text(
        "Machine Learning (æœºå™¨å­¦ä¹ ) is a subset of AI (äººå·¥æ™ºèƒ½).",
        encoding="utf-8"
    )
    files.append(mixed_file)

    return files


@pytest.fixture
def empty_document_file(tmp_path) -> Path:
    """åˆ›å»ºç©ºæ–‡æ¡£ç”¨äºæµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    file_path = tmp_path / "empty.txt"
    file_path.write_text("", encoding="utf-8")
    return file_path


@pytest.fixture
def special_chars_document_file(tmp_path) -> Path:
    """åˆ›å»ºåŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡æ¡£"""
    file_path = tmp_path / "special_chars.txt"
    content = """
    Special Characters Test:
    - Email: test@example.com
    - URL: https://example.com/path?param=value
    - Code: def func(x): return x**2
    - Math: âˆ‘ âˆ« âˆ‚ âˆ‡ âˆ
    - Emoji: ğŸ˜€ ğŸš€ ğŸ’»
    - Unicode: cafÃ© rÃ©sumÃ© naÃ¯ve
    """
    file_path.write_text(content, encoding="utf-8")
    return file_path


@pytest.fixture(scope="session")
def temp_workspace():
    """æä¾›ä¼šè¯çº§åˆ«çš„ä¸´æ—¶å·¥ä½œç©ºé—´"""
    with tempfile.TemporaryDirectory() as tmpdir:
        yield Path(tmpdir)
